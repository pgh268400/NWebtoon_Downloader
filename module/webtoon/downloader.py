import asyncio
import aiohttp
import aiofiles
import sys
import os
import time
import random
from dataclasses import dataclass, field
from typing import List, Optional
from bs4 import BeautifulSoup
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.live import Live

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
)

from module.webtoon.analyzer import EpisodeInfo, WebtoonAnalyzer
from module.headers import headers
from module.settings import Setting, FileSettingType
from module.file_processor import FileProcessor


@dataclass
class EpisodeImageInfo(EpisodeInfo):
    """ì—í”¼ì†Œë“œ ì •ë³´ + ê° ì—í”¼ì†Œë“œì˜ ì´ë¯¸ì§€ URLì„ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""

    img_urls: List[str] = field(default_factory=list)


class WebtoonDownloader:
    """ì›¹íˆ° ë‹¤ìš´ë¡œë“œ ê´€ë ¨ ê¸°ëŠ¥ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""

    # ìƒì„±ì ì²˜ë¦¬
    def __init__(
        self,
        title_id: int,
        episodes: List[EpisodeInfo],
        webtoon_title: str,
        nid_aut: Optional[str] = None,
        nid_ses: Optional[str] = None,
    ) -> None:
        #
        self.__title_id = title_id
        self.__episodes = episodes
        self.__webtoon_title = webtoon_title
        self.__detail_url = "https://comic.naver.com/webtoon/detail"

        # ì„¤ì • ë° íŒŒì¼ ì²˜ë¦¬ ê°ì²´ ì´ˆê¸°í™”
        self.__settings = Setting()
        self.__file_processor = FileProcessor()

        # ì„±ì¸ ì›¹íˆ°ìš© ì¿ í‚¤ ì„¤ì •
        self.__cookies = {}
        if nid_aut and nid_ses:
            self.__cookies = {"NID_AUT": nid_aut, "NID_SES": nid_ses}

    async def __get_episode_images(
        self, episode: EpisodeImageInfo, verbose: bool = False
    ) -> EpisodeImageInfo:
        """
        íŠ¹ì • ì—í”¼ì†Œë“œì˜ ì´ë¯¸ì§€ URLë“¤ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

        Args:
            episode: ì—í”¼ì†Œë“œ ì •ë³´
            verbose: ìƒì„¸ ì‹œê°„ ì •ë³´ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)

        Returns:
            ì´ë¯¸ì§€ URLì´ ì¶”ê°€ëœ ì—í”¼ì†Œë“œ ì •ë³´
        """
        url = f"{self.__detail_url}?titleId={self.__title_id}&no={episode.no}"

        # ìš”ì²­ ì•ˆì •ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ìµœëŒ€ 3íšŒê¹Œì§€ ì¬ì‹œë„(ì§€ìˆ˜ ë°±ì˜¤í”„) ì ìš©
        max_retries = 3
        backoff_base = 1.0  # ì´ˆ ë‹¨ìœ„, 1 -> 2 -> 4 ...

        try:
            async with aiohttp.ClientSession(
                headers=headers, cookies=self.__cookies
            ) as session:
                last_error: Optional[Exception] = None
                for attempt in range(max_retries + 1):
                    try:
                        async with session.get(url) as response:
                            if response.status == 200:
                                # HTML ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹œê°„ ì¸¡ì •
                                html_start_time = time.time()
                                html_content = await response.text()
                                html_end_time = time.time()
                                html_time = html_end_time - html_start_time

                                # BeautifulSoup íŒŒì‹± ì‹œê°„ ì¸¡ì •
                                parse_start_time = time.time()
                                soup = BeautifulSoup(html_content, "lxml")

                                # sectionContWide íƒœê·¸ ì•ˆì˜ ëª¨ë“  img íƒœê·¸ ì°¾ê¸°
                                section = soup.find("div", id="sectionContWide")
                                if section:
                                    img_tags = section.find_all("img")  # type: ignore
                                    img_urls = []

                                    for img in img_tags:
                                        src = img.get("src")  # type: ignore
                                        if src:
                                            img_urls.append(src)
                                else:
                                    img_urls = []

                                parse_end_time = time.time()
                                parse_time = parse_end_time - parse_start_time
                                total_parse_time = parse_end_time - html_start_time

                                episode.img_urls = img_urls
                                if verbose:
                                    print(
                                        f"  {episode.no}í™”: {len(img_urls)}ê°œ ì´ë¯¸ì§€ URL ìˆ˜ì§‘ ì™„ë£Œ (HTML: {html_time:.3f}s, íŒŒì‹±: {parse_time:.3f}s, ì´: {total_parse_time:.3f}s)"
                                    )
                                else:
                                    print(
                                        f"  {episode.no}í™”: {len(img_urls)}ê°œ ì´ë¯¸ì§€ URL ìˆ˜ì§‘ ì™„ë£Œ"
                                    )
                                # ì„±ê³µ ì‹œ ì¬ì‹œë„ ë£¨í”„ ì¢…ë£Œ
                                break
                            else:
                                # ë¹„ì •ìƒ ì‘ë‹µ ìƒíƒœì½”ë“œì¼ ë•Œ ì¬ì‹œë„
                                if attempt < max_retries:
                                    delay = backoff_base * (2**attempt)
                                    print(
                                        f"  {episode.no}í™”: HTTP {response.status} (ì¬ì‹œë„ {attempt+1}/{max_retries}, {delay:.1f}s ëŒ€ê¸°)"
                                    )
                                    await asyncio.sleep(delay)
                                    continue
                                else:
                                    print(
                                        f"  {episode.no}í™”: HTTP ìš”ì²­ ì‹¤íŒ¨ ({response.status}), ì¬ì‹œë„ í•œë„ ì´ˆê³¼"
                                    )
                                    episode.img_urls = []
                    except Exception as e:
                        # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë“± ì˜ˆì™¸ ë°œìƒ ì‹œ ì¬ì‹œë„
                        last_error = e
                        if attempt < max_retries:
                            delay = backoff_base * (2**attempt)
                            print(
                                f"  {episode.no}í™”: ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e} (ì¬ì‹œë„ {attempt+1}/{max_retries}, {delay:.1f}s ëŒ€ê¸°)"
                            )
                            await asyncio.sleep(delay)
                            continue
                        else:
                            print(
                                f"  {episode.no}í™”: ì´ë¯¸ì§€ URL ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e} (ì¬ì‹œë„ í•œë„ ì´ˆê³¼)"
                            )
                            episode.img_urls = []
                else:
                    # for-else: break ì—†ì´ ì¢…ë£Œëœ ê²½ìš° (ëª¨ë“  ì‹œë„ ì‹¤íŒ¨)
                    if last_error is not None:
                        print(f"  {episode.no}í™”: ìµœì¢… ì‹¤íŒ¨ - {last_error}")
                    episode.img_urls = []
        except Exception as e:
            # ì„¸ì…˜ ìƒì„± ë“± ìƒìœ„ ë ˆë²¨ ì˜ˆì™¸ ì²˜ë¦¬
            print(f"  {episode.no}í™”: ì´ë¯¸ì§€ URL ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")
            episode.img_urls = []

        return episode

    async def get_episodes_with_images_batch(
        self, episodes: List[EpisodeImageInfo], batch_size: int
    ) -> List[EpisodeImageInfo]:
        """
        ì—í”¼ì†Œë“œë“¤ì˜ ì´ë¯¸ì§€ URLì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

        Args:
            episodes: ì´ë¯¸ì§€ URLì„ ìˆ˜ì§‘í•  ì—í”¼ì†Œë“œ ë¦¬ìŠ¤íŠ¸
            batch_size: í•œ ë²ˆì— ì²˜ë¦¬í•  ì—í”¼ì†Œë“œ ìˆ˜

        Returns:
            ì´ë¯¸ì§€ URLì´ í¬í•¨ëœ ì—í”¼ì†Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        if not episodes:
            print("ìˆ˜ì§‘í•  ì—í”¼ì†Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        print(f"\n{len(episodes)}ê°œ ì—í”¼ì†Œë“œì˜ ì´ë¯¸ì§€ URLì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
        print(f"ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œì”© ì²˜ë¦¬")
        print(
            "URL ìˆ˜ì§‘ ì¤‘ ê¸¸ê²Œ ë©ˆì¶”ê±°ë‚˜ ì‘ë™í•˜ì§€ ì•Šì„ ì‹œ í”„ë¡œê·¸ë¨ ì¢…ë£Œ í›„ ì¡°ê¸ˆ ê¸°ë‹¤ë¦° í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
        )
        print(
            "URL ìˆ˜ì§‘ì— ë¬¸ì œê°€ ë§ì´ ë°œìƒí•  ê²½ìš° settings.ini íŒŒì¼ì—ì„œ batchsizeì˜ ê°’ì„ ì¤„ì´ê³  delaysecondsë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”."
        )

        episodes_with_images = []
        total_episodes = len(episodes)

        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        for i in range(0, total_episodes, batch_size):
            batch = episodes[i : i + batch_size]
            print(
                f"\në°°ì¹˜ {i//batch_size + 1}/{(total_episodes + batch_size - 1)//batch_size} ì²˜ë¦¬ ì¤‘... ({i+1}~{min(i+batch_size, total_episodes)}í™”)"
            )

            # í˜„ì¬ ë°°ì¹˜ì˜ ì´ë¯¸ì§€ URLì„ ë³‘ë ¬ë¡œ ê°€ì ¸ì˜¤ê¸°
            tasks = []
            for episode in batch:
                task = self.__get_episode_images(episode)
                tasks.append(task)

            # í˜„ì¬ ë°°ì¹˜ì˜ ìš”ì²­ì„ ë™ì‹œì— ì‹¤í–‰
            batch_results: List[EpisodeImageInfo] = await asyncio.gather(
                *tasks, return_exceptions=True
            )

            # ê²°ê³¼ ì²˜ë¦¬
            for j, result in enumerate(batch_results):
                if isinstance(result, Exception):
                    print(f"  {batch[j].no}í™”: ì˜¤ë¥˜ ë°œìƒ - {result}")
                    batch[j].img_urls = []
                    episodes_with_images.append(batch[j])
                else:
                    episodes_with_images.append(result)

            # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì ì‹œ ëŒ€ê¸°
            if i + batch_size < total_episodes:
                delay = self.__settings.delay_seconds
                print(f"ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ {delay}ì´ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
                await asyncio.sleep(delay)

        print(f"\nì´ {len(episodes_with_images)}ê°œ ì—í”¼ì†Œë“œì˜ ì´ë¯¸ì§€ URL ìˆ˜ì§‘ ì™„ë£Œ!")

        return episodes_with_images

    async def __download_single_image(
        self, session: aiohttp.ClientSession, img_url: str, file_path: Path
    ) -> bool:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜

        Args:
            session: aiohttp ì„¸ì…˜
            img_url: ì´ë¯¸ì§€ URL
            file_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ

        Returns:
            ë‹¤ìš´ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        # ìš”ì²­ ì•ˆì •ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œì— ì¬ì‹œë„(ì§€ìˆ˜ ë°±ì˜¤í”„ + ì§€í„°) ì ìš©
        max_retries = 5
        backoff_base = 1.0  # 1 -> 2 -> 4 -> 8 -> 16 ì´ˆ

        for attempt in range(max_retries + 1):
            try:
                async with session.get(img_url, headers=headers) as response:
                    if response.status == 200:
                        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
                        file_path.parent.mkdir(parents=True, exist_ok=True)

                        async with aiofiles.open(file_path, "wb") as f:
                            async for chunk in response.content.iter_chunked(8192):
                                await f.write(chunk)
                        return True
                    else:
                        # ìƒíƒœ ì½”ë“œê°€ ë¹„ì •ìƒì¸ ê²½ìš° ì¬ì‹œë„
                        if attempt < max_retries:
                            delay = backoff_base * (2**attempt)
                            # 0~20% ì§€í„° ì¶”ê°€ë¡œ ë™ì‹œ ì¬ì‹œë„ ì¶©ëŒ ë°©ì§€
                            delay *= 1 + random.uniform(0, 0.2)
                            print(
                                f"ì‹¤íŒ¨: {img_url} (HTTP {response.status}) -> ì¬ì‹œë„ {attempt+1}/{max_retries} ({delay:.1f}s ëŒ€ê¸°)"
                            )
                            await asyncio.sleep(delay)
                            continue
                        else:
                            print(
                                f"ì‹¤íŒ¨: {img_url} (HTTP {response.status}), ì¬ì‹œë„ í•œë„ ì´ˆê³¼"
                            )
                            return False
            except Exception as e:
                # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë“± ì˜ˆì™¸ ë°œìƒ ì‹œ ì¬ì‹œë„
                if attempt < max_retries:
                    delay = backoff_base * (2**attempt)
                    delay *= 1 + random.uniform(0, 0.2)
                    print(
                        f"ì˜¤ë¥˜: {img_url} - {e} -> ì¬ì‹œë„ {attempt+1}/{max_retries} ({delay:.1f}s ëŒ€ê¸°)"
                    )
                    await asyncio.sleep(delay)
                    continue
                else:
                    print(f"ì˜¤ë¥˜: {img_url} - {e} (ì¬ì‹œë„ í•œë„ ì´ˆê³¼)")
                    return False

        # ëª¨ë“  ê²½ë¡œê°€ ë°˜í™˜ë˜ë„ë¡ ì•ˆì „ë§ ë¦¬í„´ (ì •ìƒ ë™ì‘ ì¤‘ì—” ë„ë‹¬í•˜ì§€ ì•ŠìŒ)
        return False

    async def __download_all_images_concurrent(
        self, episodes: List[EpisodeImageInfo], max_concurrent: Optional[int] = None
    ) -> List[bool]:
        """
        ëª¨ë“  ì—í”¼ì†Œë“œì˜ ì´ë¯¸ì§€ë¥¼ ë™ì‹œì„± ì œí•œì„ ê±¸ì–´ í•œêº¼ë²ˆì— ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜

        Args:
            episodes: ì´ë¯¸ì§€ URLì´ í¬í•¨ëœ ì—í”¼ì†Œë“œ ë¦¬ìŠ¤íŠ¸
            max_concurrent: ìµœëŒ€ ë™ì‹œ ë‹¤ìš´ë¡œë“œ ìˆ˜ (ê¸°ë³¸ê°’: 10)

        Returns:
            ê° ì—í”¼ì†Œë“œì˜ ë‹¤ìš´ë¡œë“œ ì„±ê³µ ì—¬ë¶€ ë¦¬ìŠ¤íŠ¸
        """
        if not episodes:
            print("ë‹¤ìš´ë¡œë“œí•  ì—í”¼ì†Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # ì„¤ì •ì—ì„œ ìµœëŒ€ ë™ì‹œ ë‹¤ìš´ë¡œë“œ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
        if max_concurrent is None:
            max_concurrent = self.__settings.max_concurrent

        # ì „ì²´ ì´ë¯¸ì§€ ìˆ˜ ê³„ì‚°
        total_images = sum(len(episode.img_urls) for episode in episodes)
        print(
            f"ì´ {len(episodes)}ê°œ ì—í”¼ì†Œë“œ, {total_images}ê°œ ì´ë¯¸ì§€ë¥¼ ë™ì‹œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤..."
        )
        print(f"ìµœëŒ€ ë™ì‹œ ë‹¤ìš´ë¡œë“œ: {max_concurrent}ê°œ")

        # ì„¸ë§ˆí¬ì–´ë¡œ ì „ì²´ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë™ì‹œì„± ì œí•œ
        semaphore = asyncio.Semaphore(max_concurrent)

        async def download_single_episode_image(session, episode, img_url, img_idx):
            """ë‹¨ì¼ ì—í”¼ì†Œë“œì˜ ë‹¨ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
            async with semaphore:
                # settingsì—ì„œ folder zero fill ê°’ ê°€ì ¸ì˜¤ê¸°
                folder_zfill: int = self.__settings.get_zero_fill(
                    FileSettingType.Folder
                )

                # ê°€ì ¸ì˜¨ zero fill ê°’ ì—í”¼ì†Œë“œ ë²ˆí˜¸ì— ì ìš©
                episode_no_zfill: str = str(episode.no).zfill(folder_zfill)

                # ë‹¤ìš´ë¡œë“œ í´ë” ê²½ë¡œ ë§Œë“¤ê¸°
                download_dir: Path = (
                    Path("Webtoon_Download")
                    / self.__webtoon_title
                    / f"[{episode_no_zfill}] {episode.subtitle}"
                )

                # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ (ê¸°ë³¸ê°’: .jpg)
                ext = ".jpg"
                if "." in img_url.split("/")[-1]:
                    ext = "." + img_url.split(".")[-1].split("?")[0]

                # ë™ì¼í•˜ê²Œ settingsì—ì„œ image zero fill ê°’ ê°€ì ¸ì™€ì„œ ì´ë¯¸ì§€ íŒŒì¼ëª…ì— ì ìš©
                image_zfill: int = self.__settings.get_zero_fill(FileSettingType.Image)
                img_filename: str = str(img_idx + 1).zfill(image_zfill)
                file_path: Path = download_dir / f"{img_filename}{ext}"
                return await self.__download_single_image(session, img_url, file_path)

        try:
            async with aiohttp.ClientSession(cookies=self.__cookies) as session:
                # ëª¨ë“  ì—í”¼ì†Œë“œì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ì˜ íƒœìŠ¤í¬ ë¦¬ìŠ¤íŠ¸ë¡œ ìƒì„±
                all_tasks = []
                episode_task_counts = []  # ê° ì—í”¼ì†Œë“œë³„ íƒœìŠ¤í¬ ìˆ˜ ê¸°ë¡

                for episode in episodes:
                    if not hasattr(episode, "img_urls") or not episode.img_urls:
                        print(f"  {episode.no}í™”: ë‹¤ìš´ë¡œë“œí•  ì´ë¯¸ì§€ URLì´ ì—†ìŠµë‹ˆë‹¤.")
                        episode_task_counts.append(0)
                        continue

                    episode_task_counts.append(len(episode.img_urls))

                    # í•´ë‹¹ ì—í”¼ì†Œë“œì˜ ëª¨ë“  ì´ë¯¸ì§€ íƒœìŠ¤í¬ ìƒì„±
                    for img_idx, img_url in enumerate(episode.img_urls):
                        task = download_single_episode_image(
                            session, episode, img_url, img_idx
                        )
                        all_tasks.append(task)

                # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë™ì‹œì— ë‹¤ìš´ë¡œë“œ (ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œì„± ì œí•œ)
                print(f"\nì „ì²´ {len(all_tasks)}ê°œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
                print("=" * 60)
                all_results = await asyncio.gather(*all_tasks, return_exceptions=True)
                print("=" * 60)

                # ì—í”¼ì†Œë“œë³„ ê²°ê³¼ ì§‘ê³„
                episode_results = []
                result_idx = 0

                for i, episode in enumerate(episodes):
                    task_count = episode_task_counts[i]
                    if task_count == 0:
                        episode_results.append(False)
                        continue

                    # í•´ë‹¹ ì—í”¼ì†Œë“œì˜ ê²°ê³¼ë“¤ ì¶”ì¶œ
                    episode_task_results = all_results[
                        result_idx : result_idx + task_count
                    ]
                    result_idx += task_count

                    # ì„±ê³µ ê°œìˆ˜ ê³„ì‚°
                    success_count = sum(
                        1 for result in episode_task_results if result is True
                    )
                    episode_success = success_count == task_count
                    episode_results.append(episode_success)

                    print(f"  {episode.no}í™”: {success_count}/{task_count}ê°œ ì„±ê³µ")

                return episode_results

        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return [False] * len(episodes)

    async def download(
        self, start: int, end: int, batch_size: Optional[int] = None
    ) -> bool:
        """
        ì›¹íˆ° ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜

        Args:
            start: ì‹œì‘ í™”ìˆ˜ (1ë¶€í„° ì‹œì‘)
            end: ë í™”ìˆ˜ (1ë¶€í„° ì‹œì‘)
            batch_size: í•œ ë²ˆì— ì²˜ë¦¬í•  ë°°ì¹˜ í¬ê¸°

        Returns:
            ë‹¤ìš´ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        if not self.__episodes:
            raise ValueError("ë‹¤ìš´ë¡œë“œí•  ì—í”¼ì†Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ì„¤ì •ì—ì„œ ë°°ì¹˜ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
        if batch_size is None:
            batch_size = self.__settings.batch_size

        # 1-based indexë¥¼ 0-based indexë¡œ ë³€í™˜
        start_idx: int = start - 1
        end_idx: int = end - 1

        # ì¸ë±ìŠ¤ ë²”ìœ„ ê²€ì¦
        if start_idx < 0 or end_idx >= len(self.__episodes) or start_idx > end_idx:
            raise ValueError(
                f"ì˜ëª»ëœ í™”ìˆ˜ ë²”ìœ„ì…ë‹ˆë‹¤. (1í™” ~ {len(self.__episodes)}í™” ë²”ìœ„ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.)"
            )

        # ë‹¤ìš´ë¡œë“œ í•  ì—í”¼ì†Œë“œ ë¶€ë¶„ ì¶”ì¶œ
        selected_episodes: List[EpisodeImageInfo] = self.__episodes[
            start_idx : end_idx + 1
        ]

        # Richë¥¼ ì‚¬ìš©í•´ì„œ ì˜ˆìœ ë‹¤ìš´ë¡œë“œ ì‹œì‘ ë©”ì‹œì§€ ì¶œë ¥
        console = Console()

        # ë‹¤ìš´ë¡œë“œ ì •ë³´ í…Œì´ë¸” ìƒì„±
        table = Table(show_header=False, box=None, padding=(0, 1))
        table.add_column("ë¼ë²¨", style="cyan bold", width=25)
        table.add_column("ê°’", style="white")

        table.add_row("ì›¹íˆ° ì œëª©:", f"{self.__webtoon_title}({self.__title_id})")
        table.add_row("ì—í”¼ì†Œë“œ ìˆ˜:", f"{len(selected_episodes)}ê°œ")
        table.add_row("ë°°ì¹˜ í¬ê¸°:", str(batch_size))
        table.add_row(
            "ë‹¤ìš´ë¡œë“œ í•  ì—í”¼ì†Œë“œ:",
            f"{selected_episodes[0].no}í™” ~ {selected_episodes[-1].no}í™”",
        )

        # íŒ¨ë„ë¡œ ê°ì‹¸ì„œ ì¶œë ¥
        panel = Panel(
            table,
            title="[bold green]ğŸ“š ì›¹íˆ° ë‹¤ìš´ë¡œë“œ ì‹œì‘[/bold green]",
            border_style="green",
            padding=(1, 2),
        )
        console.print(panel)

        try:
            # EpisodeInfoë¥¼ EpisodeImageInfoë¡œ ë³€í™˜
            episode_image_infos: List[EpisodeImageInfo] = []
            for episode in selected_episodes:
                episode_image_info = EpisodeImageInfo(
                    no=episode.no,
                    subtitle=episode.subtitle,
                    thumbnail_lock=episode.thumbnail_lock,
                )
                episode_image_infos.append(episode_image_info)

            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì´ë¯¸ì§€ URL ìˆ˜ì§‘
            print("ì´ë¯¸ì§€ URL ìˆ˜ì§‘ ì‹œì‘")
            episodes_with_images = await self.get_episodes_with_images_batch(
                episode_image_infos, batch_size
            )

            console.print(
                f"\n[green]âœ“[/green] ì´ {len(episodes_with_images)}ê°œ ì—í”¼ì†Œë“œì˜ ì´ë¯¸ì§€ URL ìˆ˜ì§‘ ì™„ë£Œ!"
            )

            # ëª¨ë“  ì—í”¼ì†Œë“œì˜ ì´ë¯¸ì§€ë¥¼ í•œêº¼ë²ˆì— ë‹¤ìš´ë¡œë“œ (ë™ì‹œì„± ì œí•œ ì ìš©)
            console.print("\n[yellow]ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘[/yellow]")
            download_results = await self.__download_all_images_concurrent(
                episodes_with_images
            )

            # ê²°ê³¼ ìš”ì•½
            success_count = sum(download_results)
            total_count = len(download_results)
            success_rate = (success_count / total_count * 100) if total_count > 0 else 0

            # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
            result_table = Table(show_header=False, box=None, padding=(0, 1))
            result_table.add_column("ë¼ë²¨", style="cyan bold", width=12)
            result_table.add_column("ê°’", style="white")

            result_table.add_row("ì„±ê³µ:", f"{success_count}ê°œ")
            result_table.add_row("ì „ì²´:", f"{total_count}ê°œ")
            result_table.add_row("ì„±ê³µë¥ :", f"{success_rate:.1f}%")

            # ì„±ê³µë¥ ì— ë”°ë¼ ìƒ‰ìƒ ë° ì•„ì´ì½˜ ê²°ì •
            if success_rate == 100:
                title_style = "bold green"
                icon = "ğŸ‰"
                border_color = "green"
            elif success_rate >= 80:
                title_style = "bold yellow"
                icon = "âœ…"
                border_color = "yellow"
            else:
                title_style = "bold red"
                icon = "âš ï¸"
                border_color = "red"

            result_panel = Panel(
                result_table,
                title=f"[{title_style}]{icon} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ[/{title_style}]",
                border_style=border_color,
                padding=(1, 2),
            )
            console.print(result_panel)

            return success_rate == 100

        except Exception as e:
            console.print(f"[red]âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}[/red]")
            import traceback

            traceback.print_exc()
            return False

    @property
    def title_id(self) -> int:
        """íƒ€ì´í‹€ id"""
        return self.__title_id

    @property
    def episodes(self) -> List[EpisodeInfo]:
        """ë‹¤ìš´ë¡œë“œ í•  ì—í”¼ì†Œë“œ ë¦¬ìŠ¤íŠ¸"""
        return self.__episodes

    @property
    def nid_aut(self) -> Optional[str]:
        """NID_AUT ì¿ í‚¤ ê°’"""
        return self.__cookies.get("NID_AUT")

    @property
    def nid_ses(self) -> Optional[str]:
        """NID_SES ì¿ í‚¤ ê°’"""
        return self.__cookies.get("NID_SES")


# WebtoonDownloader í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_downloader(title_id: int, start: int, end: int):
    """WebtoonDownloaderì˜ download() í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸"""
    try:
        # Richë¥¼ ì‚¬ìš©í•´ì„œ ì›¹íˆ° ì •ë³´ ìˆ˜ì§‘ ê³¼ì •ì„ í‘œì‹œ (í•˜ë‚˜ì˜ íŒ¨ë„ì—ì„œ ìƒíƒœ ê°±ì‹ )
        console = Console()

        def analyzer_panel(title_id, analyzer=None) -> Panel:
            done = analyzer is not None
            collecting = "[yellow]ğŸ“¡ ì›¹íˆ° ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...[/yellow]"
            completed = "[green]âœ… ì›¹íˆ° ì •ë³´ ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤![/green]"

            table = Table(show_header=False, box=None, padding=(0, 1))
            table.add_column("ë¼ë²¨", style="cyan bold", width=15)
            table.add_column("ê°’", style="white")

            if done:
                table.add_row("ì›¹íˆ° ì œëª©:", analyzer.title_name)
                table.add_row(
                    "ì´ ì—í”¼ì†Œë“œ:", f"{len(analyzer.downloadable_episodes)}í™”"
                )
                table.add_row("ìƒíƒœ:", f"{collecting}\n{completed}")
            else:
                table.add_row("íƒ€ì´í‹€ ID:", str(title_id))
                table.add_row("ìƒíƒœ:", collecting)

            return Panel(
                table,
                title=(
                    "[bold green]âœ”ï¸  ë¶„ì„ ì™„ë£Œ[/bold green]"
                    if done
                    else "[bold blue]ğŸ” ì›¹íˆ° ë¶„ì„ ì¤‘[/bold blue]"
                ),
                border_style="green" if done else "blue",
                padding=(1, 2),
            )

        # Liveë¡œ ë™ì¼ íŒ¨ë„ ê°±ì‹ 
        with Live(
            analyzer_panel(title_id), console=console, refresh_per_second=4
        ) as live:
            analyzer = await WebtoonAnalyzer.create(title_id)
            live.update(analyzer_panel(title_id, analyzer))

        # ì„±ì¸ ì›¹íˆ° ì¸ì¦ìš© ì¿ í‚¤
        nid_aut: Optional[str] = None
        nid_ses: Optional[str] = None

        if analyzer.is_adult:
            print("ì„±ì¸ ì›¹íˆ°ì…ë‹ˆë‹¤. ë¡œê·¸ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            print("NID_AUTì™€ NID_SES ì¿ í‚¤ ê°’ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

            nid_aut = input("NID_AUT: ").strip()
            nid_ses = input("NID_SES: ").strip()

            if not nid_aut or not nid_ses:
                print("NID_AUTì™€ NID_SES ê°’ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.")
                return

        # ë‹¤ìš´ë¡œë”ë¡œ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
        downloader = WebtoonDownloader(
            analyzer.title_id,
            analyzer.downloadable_episodes,
            analyzer.title_name,
            nid_aut,
            nid_ses,
        )

        success = await downloader.download(start, end)
        print(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}")

    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


async def test_case():
    """WebtoonDownloader í…ŒìŠ¤íŠ¸ - ì§€ì •ëœ title IDë“¤ë¡œ í…ŒìŠ¤íŠ¸"""
    # í…ŒìŠ¤íŠ¸í•  title idë“¤ê³¼ í™”ìˆ˜ ë²”ìœ„
    test_cases = [
        # (835801, 1, 2),  # ë‹¬ë§ˆê±´
        (183559, 1, 10),  # ì‹ ì˜ íƒ‘
        # (602287, 1, 2),  # ë·°í‹°í’€ êµ°ë°”ë¦¬
    ]

    for title_id, start, end in test_cases:
        await test_downloader(title_id, start, end)


# ë©”ì¸ ì‹¤í–‰ë¶€
if __name__ == "__main__":
    asyncio.run(test_case())
